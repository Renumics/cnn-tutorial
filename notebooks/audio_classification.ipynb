{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio classification with pre-trained transformer models\n",
    "In this tutorial we will see how to leverage pre-trained transformer models to quickly build a data-efficient audio classification model.<br>\n",
    "We will compute an embedding for given audio dataset and use the embedding as the feature vector for a simple classification with a support vector machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "ds_full = datasets.load_dataset(\"renumics/esc50\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renumics import spotlight\n",
    "\n",
    "spotlight.show(ds_full, port=8889, no_ssl=True, host=\"0.0.0.0\", analyze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We extract a small dataset for the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label number 42 are sirens\n",
    "ds_siren = ds_full.shuffle(seed=42).filter(lambda x: x[\"label\"] == 42)\n",
    "ds_non_siren = ds_full.select(range(80)).filter(lambda x: x[\"label\"] != 42).select(range(40))\n",
    "\n",
    "ds = datasets.concatenate_datasets([ds_siren, ds_non_siren])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the embedding with Huggingface ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to cast the waveforms to a uniform sampling rate of 16kHz\n",
    "ds = ds.cast_column(\"audio\", datasets.Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def extract_embeddings(model, feature_extractor, audio_name=\"audio\"):\n",
    "    \"\"\"Utility to compute embeddings.\"\"\"\n",
    "    device = model.device\n",
    "\n",
    "    def pp(batch):\n",
    "        waveform = batch[audio_name]\n",
    "\n",
    "        inputs = feature_extractor(\n",
    "            waveform[\"array\"], sampling_rate=waveform[\"sampling_rate\"], return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Get the embeddings\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(**inputs, output_hidden_states=True).hidden_states[-1][0, 0, :].cpu()\n",
    "\n",
    "        return {\"embedding\": embeddings}\n",
    "\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ASTFeatureExtractor, ASTForAudioClassification\n",
    "\n",
    "# Load the pre-trained Audio Spectrogram Transformer model and feature extractor\n",
    "model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "model = ASTForAudioClassification.from_pretrained(model_name)\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "extract_fn = extract_embeddings(model.to(device), feature_extractor, \"audio\")\n",
    "ds_enriched = ds.map(extract_fn, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a classification with a support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# convert to pandas\n",
    "df = ds_enriched.to_pandas()\n",
    "df['binary_label'] = df['label'].apply(lambda x: 1 if x == 42 else 0)\n",
    "\n",
    "# Separate the features and the label\n",
    "X = [x.tolist() for x in df[\"embedding\"]]\n",
    "y = df[\"binary_label\"]\n",
    "\n",
    "# Split the data into training and test sets (e.g., 80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Support Vector Classifier\n",
    "svc = SVC(kernel=\"linear\", random_state=42)  # Use 'linear' kernel, or try 'rbf', 'poly', etc.\n",
    "\n",
    "# Train the model\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Print a classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Print a confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative analysis with Spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the full dataset\n",
    "y_pred = svc.predict(X)\n",
    "\n",
    "#add the predictions to the dataset\n",
    "df['prediction'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotlight.show(df, port=8889, no_ssl=True, host=\"0.0.0.0\", analyze=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
