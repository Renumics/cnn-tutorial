{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "Unsupervised learning can be a handy tool. What's best is: it does not require any labeled data.\n",
    "One popular type of unsupervised learning models are autoencoders.\n",
    "They learn efficient data encodings by compressing the data into a low dimensional representation and subsequently trying to reproduce the original input from that learned representation as best as possible.\n",
    "Autoencoders are used for all kinds of tasks that involve dimensionality reduction.\n",
    "The applications include data visualization, data denoising, anomaly detection and information retrieval.\n",
    "\n",
    "Today we will focus on the last one: information retrieval. We will use autoencoders to learn low dimensional encodings for the CAD models of the DMU-Net dataset. We will then apply a simple k-nearest-neighbors algorithm to the encodings in order to retrieve the most similar CAD models for a given model. Let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib renumics-spotlight scipy umap-learn k3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining imports\n",
    "The imports are the same as in the 3D classification tutorial, with the addition of `sklearn` for the k-nearst-neighbors algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import k3d\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "from ipywidgets import GridspecLayout, Label, VBox\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.layers import Conv3D, Input, MaxPool3D, UpSampling3D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "pyarrow.PyExtensionType.set_auto_load(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "Again, we load and process the DMU-Net dataset. This time we only need the input data, no labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset(\"renumics/dmu_tiny\")\n",
    "ds_train = ds[\"train\"]\n",
    "ds_test = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Nut\", \"Screw\", \"GearWheel\"]\n",
    "\n",
    "train_geometries = np.array(ds_train[\"voxel\"])\n",
    "train_labels = np.array(ds_train[\"label\"])\n",
    "\n",
    "test_geometries = np.array(ds_test[\"voxel\"])\n",
    "test_labels = np.array(ds_test[\"label\"])\n",
    "test_ids = np.array(ds_test[\"id\"])\n",
    "\n",
    "train_geometries = train_geometries.reshape(*train_geometries.shape, 1)\n",
    "test_geometries = test_geometries.reshape(*test_geometries.shape, 1)\n",
    "all_geometries = np.append(test_geometries, train_geometries, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "Now we build the autoencoder. The architecture basically consists of an encoder and a decoder. The encoder compresses the input data into a low dimensional representation. The decoder tries to recover the original data.\n",
    "![](imgs/autoencoder.png)\n",
    "*Architecture of an autoencoder. [Source.](https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798)*\n",
    "\n",
    "For our task we compress the <tt>48x48x48</tt> geometric shapes into a <tt>12x12x12x8</tt> encoding. This gives us  a dimensionality reduction of factor 8. For a higher reduction we would need more training time and possibly more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_geometry = Input((48, 48, 48, 1))\n",
    "x = Conv3D(filters=16, kernel_size=(3, 3, 3), padding=\"same\", activation=\"relu\")(input_geometry)\n",
    "x = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "x = Conv3D(filters=8, kernel_size=(3, 3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "encoded = MaxPool3D(pool_size=(2, 2, 2))(x)\n",
    "\n",
    "x = Conv3D(filters=8, kernel_size=(3, 3, 3), padding=\"same\", activation=\"relu\")(encoded)\n",
    "x = UpSampling3D(size=(2, 2, 2))(x)\n",
    "x = Conv3D(filters=16, kernel_size=(3, 3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = UpSampling3D(size=(2, 2, 2))(x)\n",
    "decoded = Conv3D(filters=1, kernel_size=(3, 3, 3), padding=\"same\", activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoder has a simple CNN architecture, consisting of 2 convolutions followed by pooling operations. The architecture of the decoder is basically inverse to the encoder. The <tt>UpSampling3D</tt> layer simply doubles the dimensions by repeating each value across a local patch of size <tt>2x2</tt>.\n",
    "\n",
    "The autoencoder consists of the encoder followed by the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_geometry, decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We train the autoencoder by defining the geometric shapes as both input and output of the model. Thus, the model learns to construct (and recover) a low dimensional representation that encodes the essential features of the data.\n",
    "\n",
    "This time we need to train a bit longer to obtain good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    train_geometries,\n",
    "    train_geometries,\n",
    "    validation_data=(test_geometries, test_geometries),\n",
    "    epochs=20,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Reconstructions\n",
    "We have now trained both an encoder and a decoder for our CAD models. We can examine the quality of the learned encodings by looking at how well the decoder was able to reconstruct the general shape of the geometries. You should be able to still recognize the model classes.  If you have the time, you can try to increase the number of training epochs, that should further improve your encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test_geometries)\n",
    "reconstructions = predictions >= 0.5\n",
    "rows, cols = 4, 3\n",
    "grid = GridspecLayout(rows, cols)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        sample_idx = i * cols + j\n",
    "        plot = k3d.plot(height=300, menu_visibility=False, grid_visible=False)\n",
    "        plot += k3d.voxels(\n",
    "            reconstructions[sample_idx].squeeze().astype(np.uint8), bounds=[0, 1, 0, 1, 0, 1]\n",
    "        )\n",
    "        grid[i, j] = VBox([plot])\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval\n",
    "For the shape retrieval we are only interested in the first half of the autoencoder: the encoder.\n",
    "The task is to retrieve the most similar geometries for a test geometry.\n",
    "We use the trained encoder model to extract encodings for the CAD geometries. The codes are flattened into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_geometry, encoded)\n",
    "train_codes = encoder.predict(train_geometries)\n",
    "train_codes = train_codes.reshape(-1, np.prod(train_codes[0].shape))\n",
    "test_shape = test_geometries[0]\n",
    "test_code = encoder.predict(test_shape[None])\n",
    "test_code = test_code.reshape(-1, np.prod(test_code.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the encodings to compare and search for the most similar geometries for the given geometry.\n",
    "We use a k-nearest-neighbor algorithm to retrieve the 3 most similar items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric=\"euclidean\")\n",
    "knn.fit(train_codes)\n",
    "neighbor_distances, neighbor_indices = knn.kneighbors(test_code, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the given geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Queried geometric shape\")\n",
    "plot = k3d.plot(menu_visibility=False)\n",
    "plot += k3d.voxels(test_shape.astype(np.uint8), bounds=[0, 1, 0, 1, 0, 1])\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the retrieved shapes. If all went well they should have a strong resemblance to the queried shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Retrieved similar shapes\")\n",
    "grid = GridspecLayout(1, 3)\n",
    "for j in range(3):\n",
    "    sample_idx = neighbor_indices[0, j]\n",
    "    plot = k3d.plot(height=300, menu_visibility=False, grid_visible=False)\n",
    "    plot += k3d.voxels(train_geometries[sample_idx].astype(np.uint8), bounds=[0, 1, 0, 1, 0, 1])\n",
    "    grid[0, j] = VBox([Label(value=\"Distance: {:.2f}\".format(neighbor_distances[0, j])), plot])\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last of the tutorials. You have constructed a whole 3D shape retrieval system, based on low dimensional encodings generated by autoencoders. Hopefully the tutorials have helped you gain a general sense of working with neural networks. Cheers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 699,
   "position": {
    "height": "40px",
    "left": "1445px",
    "right": "20px",
    "top": "109px",
    "width": "478px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
