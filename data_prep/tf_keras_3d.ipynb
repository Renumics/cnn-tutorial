{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 2D to 3D\n",
    "If you have completed the 2D MNIST notebook tutorial, you already know how to build a simple classifier for images. But there is only so much you can do with images. Instead, we want to focus on <tt>3D</tt> objects. So how exactly can one learn on <tt>3D</tt> geometry?<br>\n",
    "For <tt>2D</tt> the data representation is straight forward: images. For <tt>3D</tt> we have multiple possibilities: voxelgrids, point clouds, meshes, multiview-based approaches, just to name a few. In this tutorial we will be using a voxelgrid, which is basically an image with <tt>3D</tt> pixels (voxel cells).\n",
    "\n",
    "This tutorial will be a bit more hands-on than the last one, as you will transform the <tt>2D</tt> network of the previous MNIST tutorial into a <tt>3D</tt> network yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow matplotlib renumics-spotlight scipy umap-learn k3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining imports\n",
    "Again, we start by defining some imports. We will use the new imports `k3d` and `ipywidgets` for <tt>3D</tt> plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import k3d\n",
    "import numpy as np\n",
    "from ipywidgets import GridspecLayout, Label, VBox\n",
    "from tensorflow.keras.layers import Conv3D, Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "This time the dataset is a bit more interesting.\n",
    "We use a subset of the DMU-Net dataset, a research dataset of engineering CAD models.\n",
    "![](imgs/dmunet.png)\n",
    "*Some DMU-Net examples. [Source.](https://www.researchgate.net/publication/325170238_Deep_learning_for_big_data_applications_in_CAD_and_PLM_-_Research_review_opportunities_and_case_study)*\n",
    "\n",
    "We train on 3 simple classes: Nuts, Screws and Gear Wheels.\n",
    "The dataset is already processed for you and saved as voxelgrids of size <tt>48x48x48</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset(\"renumics/dmu_tiny\")\n",
    "ds_train = ds[\"train\"]\n",
    "ds_test = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba412edeaec14018bf5fbaa530f848d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Spotlight running on http://127.0.0.1:62177/'), HBox(children=(Button(description=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from renumics import spotlight\n",
    "\n",
    "spotlight.show(ds, dtype={\"mesh\": spotlight.Mesh, \"mesh_voxelized\": spotlight.Mesh})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292, 48, 48, 48)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_geometries = np.array(ds_train[\"voxel\"])\n",
    "train_geometries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Nut\", \"Screw\", \"GearWheel\"]\n",
    "train_geometries = np.array(ds_train[\"voxel\"])\n",
    "train_labels = ds_train[\"label\"]\n",
    "test_geometries = np.array(ds_test[\"voxel\"])\n",
    "test_labels = ds_test[\"label\"]\n",
    "# test_geometries, test_labels, test_ids = data['test_geometries'], data['test_labels'], data['test_ids']\n",
    "train_geometries = train_geometries.reshape(*train_geometries.shape, 1)\n",
    "test_geometries = test_geometries.reshape(*test_geometries.shape, 1)\n",
    "all_geometries = np.append(test_geometries, train_geometries, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's view an example from the train set, this time in 3D. You can zoom, shift and rotate as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Screw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859c730c1a664df48233292dd77a3ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 5\n",
    "print(\"Label: \" + class_names[train_labels[sample_idx]])\n",
    "plot = k3d.plot(menu_visibility=False)\n",
    "plot += k3d.voxels(\n",
    "    train_geometries[sample_idx].squeeze().astype(np.uint8), bounds=[0, 1, 0, 1, 0, 1]\n",
    ")\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "This is where you need to write your own code, or at least make some small code changes. The lines of the following code cells are simply copied from the <tt>2D</tt> MNIST tutorial. Your job is to make them work for the brandnew <tt>3D</tt> DMU-Net dataset. If you missed some changes you'll get according error messages along the way.\n",
    "<br>\n",
    "Make all appropriate changes to adapt the MNIST model layers to the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_geometry = Input((48, 48, 1))\n",
    "x = Conv3D(filters=16, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(input_geometry)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Conv3D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=128, activation=\"relu\")(x)\n",
    "class_probs = Dense(units=10, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details style=\\\"border-radius: 2px;border:1px solid #55AA55;background:#CCFFCC;\\\">\n",
    "<summary>Click for solution.</summary>\n",
    "Change the input shape to <tt>48x48x48x1</tt>.<br>\n",
    "Replace all <tt>Conv2d</tt> and <tt>MaxPool2D</tt> layers with <tt>Conv3D</tt> and <tt>MaxPool3D</tt> layers, respectively.<br>\n",
    "Add a third dimension to <tt>kernel_size</tt> and <tt>pool_size</tt>.<br>\n",
    "    Change the number of output units to <tt>3</tt>.\n",
    "</details>\n",
    "\n",
    "These changes were pretty easy. However, you should also be aware of how the dimensions of the tensors change throughout the layers, from input to output. Can you guess the tensor shape right before the <tt>Flatten</tt> layer?\n",
    "<details style=\\\"border-radius: 2px;border:1px solid #55AA55;background:#CCFFCC;\\\">\n",
    "<summary>Click for solution.</summary>\n",
    "The tensor shape is <tt>12x12x32</tt>.<br>\n",
    "The input shape is <tt>48x48x48x1</tt>. We apply max pooling twice, which each halves the input shape dimensions. The current filter size is <tt>32</tt>.\n",
    "</details>\n",
    "\n",
    "That are all the changes you need to make. Now we construct and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_geometry, class_probs)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Again, we train the model. This time we have a much smaller dataset to train on, but as we are working in 3D, the training does take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_geometries,\n",
    "    train_labels,\n",
    "    validation_data=(test_geometries, test_labels),\n",
    "    epochs=5,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Lastly, we visualize some test samples and their respective predicted class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_geometries)\n",
    "rows, cols = 4, 3\n",
    "grid = GridspecLayout(rows, cols)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        sample_idx = i * cols + j\n",
    "        plot = k3d.plot(height=300, menu_visibility=False, grid_visible=False)\n",
    "        plot += k3d.voxels(\n",
    "            test_geometries[sample_idx].squeeze().astype(np.uint8), bounds=[0, 1, 0, 1, 0, 1]\n",
    "        )\n",
    "        grid[i, j] = VBox(\n",
    "            [\n",
    "                Label(\n",
    "                    value=\"Pred: {} ({:.2f}), Label: {} ({:.2f})\".format(\n",
    "                        class_names[np.argmax(predictions[sample_idx])],\n",
    "                        predictions[sample_idx, np.argmax(predictions[sample_idx])],\n",
    "                        class_names[test_labels[sample_idx]],\n",
    "                        predictions[sample_idx, test_labels[sample_idx]],\n",
    "                    )\n",
    "                ),\n",
    "                plot,\n",
    "            ]\n",
    "        )\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the wrong samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_indices = (np.argmax(predictions, axis=-1) != test_labels).nonzero()[0]\n",
    "rows, cols = 4, 2\n",
    "grid = GridspecLayout(rows, cols)\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        if i * cols + j >= len(wrong_indices):\n",
    "            break\n",
    "        sample_idx = wrong_indices[i * cols + j]\n",
    "        plot = k3d.plot(height=300, menu_visibility=False, grid_visible=False)\n",
    "        plot += k3d.voxels(\n",
    "            test_geometries[sample_idx].squeeze().astype(np.uint8), bounds=[0, 1, 0, 1, 0, 1]\n",
    "        )\n",
    "        grid[i, j] = VBox(\n",
    "            [\n",
    "                Label(\n",
    "                    value=\"{} | Pred: {} ({:.2f}), Label: {} ({:.2f})\".format(\n",
    "                        test_ids[sample_idx],\n",
    "                        class_names[np.argmax(predictions[sample_idx])],\n",
    "                        predictions[sample_idx, np.argmax(predictions[sample_idx])],\n",
    "                        class_names[test_labels[sample_idx]],\n",
    "                        predictions[sample_idx, test_labels[sample_idx]],\n",
    "                    )\n",
    "                ),\n",
    "                plot,\n",
    "            ]\n",
    "        )\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great work, you managed to build and train your first simple <tt>3D</tt> model for voxelgrids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qualitative analysis of the model\n",
    "In order to interpret the model results, we compute several additional outputs:\n",
    "- We take the output of the last CNN-layer as a similarity measure (\"embedding\")\n",
    "- We compute the entropy of the softmax layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copyfile(\"dmu_dataset_base.h5\", \"dmu_dataset.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "embedding_model = Model(input_geometry, head)\n",
    "predicted_embeddings = embedding_model.predict(all_geometries)\n",
    "predictions_softmax = model.predict(all_geometries)\n",
    "predictions = np.argmax(predictions_softmax, axis=1)\n",
    "entropies = stats.distributions.entropy(predictions_softmax, axis=1)\n",
    "\n",
    "false = predictions != all_labels\n",
    "\n",
    "with Dataset(\"dmu_dataset.h5\", \"a\") as dataset:\n",
    "    dataset.append_float_column(\"entropy_1\", entropies)\n",
    "    dataset.append_categorical_column(\"prediction_1\", [\"0\", \"1\", \"2\"], predictions.astype(\"U\"))\n",
    "    dataset.append_embedding_column(\"embedding_1\", predicted_embeddings)\n",
    "    dataset.append_int_column(\"false_1\", false.astype(int))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 517,
   "position": {
    "height": "40px",
    "left": "1544px",
    "right": "20px",
    "top": "107px",
    "width": "311px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
